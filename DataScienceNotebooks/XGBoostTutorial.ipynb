{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using XGBoost\n",
    "\n",
    "\n",
    " - https://cambridgespark.com/content/tutorials/hyperparameter-tuning-in-xgboost/index.html\n",
    " - http://xgboost.readthedocs.io/en/latest//parameter.html\n",
    " - https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facebook Comment Volume Dataset Data Set \n",
    "\n",
    " - https://archive.ics.uci.edu/ml/machine-learning-databases/00363/\n",
    " \n",
    "This dataset is composed of 53 features describing a post on Facebook: the number of likes on the page it was posted, the category of the page, the time and day it was posted, etc. The last column is the target: the number of comments the post received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = \"Dataset/Training/Features_Variant_1.csv\"\n",
    "df = pd.read_csv(file,header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>11.291045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.495138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>11.291045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.495138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>11.291045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.495138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>11.291045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.495138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>11.291045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.495138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1    2   3    4      5          6    7          8    9  ...  44  \\\n",
       "0  634995   0  463   1  0.0  806.0  11.291045  1.0  70.495138  0.0 ...   0   \n",
       "1  634995   0  463   1  0.0  806.0  11.291045  1.0  70.495138  0.0 ...   0   \n",
       "2  634995   0  463   1  0.0  806.0  11.291045  1.0  70.495138  0.0 ...   1   \n",
       "3  634995   0  463   1  0.0  806.0  11.291045  1.0  70.495138  0.0 ...   1   \n",
       "4  634995   0  463   1  0.0  806.0  11.291045  1.0  70.495138  0.0 ...   0   \n",
       "\n",
       "   45  46  47  48  49  50  51  52  53  \n",
       "0   0   0   0   0   0   0   0   1   0  \n",
       "1   0   0   0   0   0   0   1   0   0  \n",
       "2   0   0   0   0   0   0   0   1   0  \n",
       "3   0   0   1   0   0   0   0   0   0  \n",
       "4   0   0   0   0   1   0   0   0   0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 40949 entries and 54 features\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset has {} entries and {} features\".format(*df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.loc[:,:52].values\n",
    "y = df.loc[:,53].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading into DMatrices\n",
    "dtrain = xgb.DMatrix(X_train,label=y_train)\n",
    "dtest = xgb.DMatrix(X_test,label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MAE is 11.31\n"
     ]
    }
   ],
   "source": [
    "#Build a simple baseline model using MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#get mean value\n",
    "mean_train = np.mean(y_train)\n",
    "\n",
    "#get predictions on test set\n",
    "baseline_pred = np.ones(y_test.shape)*mean_train\n",
    "\n",
    "#compute MAE\n",
    "mae_base = mean_absolute_error(y_test,baseline_pred)\n",
    "\n",
    "print(\"Baseline MAE is {:.2f}\".format(mae_base))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Tuning XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will tune 6 of the hyperparameters that are usually having a big impact on performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#params dictionary\n",
    "params = {\n",
    "        'max_depth':6,\n",
    "        'min_child_weight':1,\n",
    "        'eta':0.3,\n",
    "        'subsample':1,\n",
    "        'colsample_bytree':1,\n",
    "        #other parameters\n",
    "        'objective':'reg:linear',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost provides a nice way to find the best number of rounds whilst training. Since trees are built sequentially, instead of fixing the number of rounds at the beginning, we can test our model at each step and see if adding a new tree/round improves performance.\n",
    "\n",
    "To do so, we define a test dataset and a metric that is used to assess performance at each round. If performance haven't improved for N rounds (N is defined by the variable early_stopping_round), we stop the training and keep the best number of boosting rounds. Let's see how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to add the evaluation metric we are interested in to our params dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['eval_metric'] = \"mae\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still need to pass a num_boost_round which corresponds to the maximum number of boosting rounds that we allow. We set it to a large value hoping to find the optimal number of rounds before reaching it, if we haven't improved performance on our test dataset in early_stopping_round rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_boost_round = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to automatically find the best number of boosting rounds, we need to pass extra parameters on top of the params dictionary, the training DMatrix and num_boost_round:\n",
    "\n",
    " - evals: a list of pairs (test_dmatrix, name_of_test). Here we will use our dtest DMatrix.\n",
    " - early_stopping_rounds: The number of rounds without improvements after which we should stop, here we set it to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:5.97478\n",
      "Will train until Test-mae hasn't improved in 10 rounds.\n",
      "[1]\tTest-mae:5.03359\n",
      "[2]\tTest-mae:4.64572\n",
      "[3]\tTest-mae:4.42331\n",
      "[4]\tTest-mae:4.39328\n",
      "[5]\tTest-mae:4.35544\n",
      "[6]\tTest-mae:4.31315\n",
      "[7]\tTest-mae:4.33087\n",
      "[8]\tTest-mae:4.37164\n",
      "[9]\tTest-mae:4.38774\n",
      "[10]\tTest-mae:4.39443\n",
      "[11]\tTest-mae:4.40661\n",
      "[12]\tTest-mae:4.39124\n",
      "[13]\tTest-mae:4.39088\n",
      "[14]\tTest-mae:4.39827\n",
      "[15]\tTest-mae:4.39104\n",
      "[16]\tTest-mae:4.40307\n",
      "Stopping. Best iteration:\n",
      "[6]\tTest-mae:4.31315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using XGBoost's CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In order to tune the other hyperparameters, we will use the cv function from XGBoost. It allows us to run cross-validation on our training dataset and returns a mean MAE score.\n",
    "\n",
    "We need to pass it:\n",
    "\n",
    "params: our dictionary of parameters.\n",
    "our dtrain matrix.\n",
    "num_boost_round: number of boosting rounds. Here we will use a large number again and count on early_stopping_rounds to find the optimal number of rounds before reaching the maximum.\n",
    "seed: random seed. It's important to set a seed here, to ensure we are using the same folds for each step so we can properly compare the scores with different parameters.\n",
    "nfold: the number of folds to use for cross-validation\n",
    "metrics: the metrics to use to evaluate our model, here we use MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-mae-mean</th>\n",
       "      <th>test-mae-std</th>\n",
       "      <th>train-mae-mean</th>\n",
       "      <th>train-mae-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.689189</td>\n",
       "      <td>0.270149</td>\n",
       "      <td>5.604765</td>\n",
       "      <td>0.064495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.849525</td>\n",
       "      <td>0.271883</td>\n",
       "      <td>4.622477</td>\n",
       "      <td>0.065106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.468342</td>\n",
       "      <td>0.239475</td>\n",
       "      <td>4.059710</td>\n",
       "      <td>0.065772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.268584</td>\n",
       "      <td>0.224462</td>\n",
       "      <td>3.722983</td>\n",
       "      <td>0.060820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.192448</td>\n",
       "      <td>0.189762</td>\n",
       "      <td>3.510303</td>\n",
       "      <td>0.061203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.172856</td>\n",
       "      <td>0.189612</td>\n",
       "      <td>3.367213</td>\n",
       "      <td>0.061021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.157860</td>\n",
       "      <td>0.192572</td>\n",
       "      <td>3.245549</td>\n",
       "      <td>0.060276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.143254</td>\n",
       "      <td>0.194440</td>\n",
       "      <td>3.151495</td>\n",
       "      <td>0.062612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.147843</td>\n",
       "      <td>0.196197</td>\n",
       "      <td>3.082321</td>\n",
       "      <td>0.059020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.144657</td>\n",
       "      <td>0.189785</td>\n",
       "      <td>3.016803</td>\n",
       "      <td>0.057321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.151564</td>\n",
       "      <td>0.184621</td>\n",
       "      <td>2.974848</td>\n",
       "      <td>0.048560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.153975</td>\n",
       "      <td>0.192428</td>\n",
       "      <td>2.929269</td>\n",
       "      <td>0.034235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.154961</td>\n",
       "      <td>0.192741</td>\n",
       "      <td>2.900030</td>\n",
       "      <td>0.037107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.150087</td>\n",
       "      <td>0.185076</td>\n",
       "      <td>2.870198</td>\n",
       "      <td>0.039780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.156701</td>\n",
       "      <td>0.188260</td>\n",
       "      <td>2.846479</td>\n",
       "      <td>0.037792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.145404</td>\n",
       "      <td>0.184212</td>\n",
       "      <td>2.811917</td>\n",
       "      <td>0.036969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.141670</td>\n",
       "      <td>0.183382</td>\n",
       "      <td>2.791487</td>\n",
       "      <td>0.034505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.139406</td>\n",
       "      <td>0.191476</td>\n",
       "      <td>2.764857</td>\n",
       "      <td>0.032798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.134138</td>\n",
       "      <td>0.196838</td>\n",
       "      <td>2.730498</td>\n",
       "      <td>0.030304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.120616</td>\n",
       "      <td>0.194074</td>\n",
       "      <td>2.686291</td>\n",
       "      <td>0.025828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.115625</td>\n",
       "      <td>0.190053</td>\n",
       "      <td>2.661713</td>\n",
       "      <td>0.024625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.111492</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>2.632685</td>\n",
       "      <td>0.026922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.106884</td>\n",
       "      <td>0.188216</td>\n",
       "      <td>2.598391</td>\n",
       "      <td>0.026591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.109425</td>\n",
       "      <td>0.189713</td>\n",
       "      <td>2.575809</td>\n",
       "      <td>0.034930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.106895</td>\n",
       "      <td>0.185098</td>\n",
       "      <td>2.544730</td>\n",
       "      <td>0.030703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.103488</td>\n",
       "      <td>0.185234</td>\n",
       "      <td>2.525501</td>\n",
       "      <td>0.031801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.098627</td>\n",
       "      <td>0.186998</td>\n",
       "      <td>2.500908</td>\n",
       "      <td>0.027606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.098459</td>\n",
       "      <td>0.185767</td>\n",
       "      <td>2.478799</td>\n",
       "      <td>0.029692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.098721</td>\n",
       "      <td>0.186931</td>\n",
       "      <td>2.457476</td>\n",
       "      <td>0.027944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.093534</td>\n",
       "      <td>0.187031</td>\n",
       "      <td>2.433839</td>\n",
       "      <td>0.019612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.092398</td>\n",
       "      <td>0.190349</td>\n",
       "      <td>2.413498</td>\n",
       "      <td>0.019445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.092814</td>\n",
       "      <td>0.189468</td>\n",
       "      <td>2.398102</td>\n",
       "      <td>0.020367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4.094014</td>\n",
       "      <td>0.191986</td>\n",
       "      <td>2.373646</td>\n",
       "      <td>0.023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.090828</td>\n",
       "      <td>0.183624</td>\n",
       "      <td>2.354041</td>\n",
       "      <td>0.021126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.091551</td>\n",
       "      <td>0.183067</td>\n",
       "      <td>2.341457</td>\n",
       "      <td>0.014121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4.092410</td>\n",
       "      <td>0.179464</td>\n",
       "      <td>2.325629</td>\n",
       "      <td>0.011132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.086722</td>\n",
       "      <td>0.183275</td>\n",
       "      <td>2.307251</td>\n",
       "      <td>0.014028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.082788</td>\n",
       "      <td>0.184458</td>\n",
       "      <td>2.292440</td>\n",
       "      <td>0.011218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test-mae-mean  test-mae-std  train-mae-mean  train-mae-std\n",
       "0        5.689189      0.270149        5.604765       0.064495\n",
       "1        4.849525      0.271883        4.622477       0.065106\n",
       "2        4.468342      0.239475        4.059710       0.065772\n",
       "3        4.268584      0.224462        3.722983       0.060820\n",
       "4        4.192448      0.189762        3.510303       0.061203\n",
       "5        4.172856      0.189612        3.367213       0.061021\n",
       "6        4.157860      0.192572        3.245549       0.060276\n",
       "7        4.143254      0.194440        3.151495       0.062612\n",
       "8        4.147843      0.196197        3.082321       0.059020\n",
       "9        4.144657      0.189785        3.016803       0.057321\n",
       "10       4.151564      0.184621        2.974848       0.048560\n",
       "11       4.153975      0.192428        2.929269       0.034235\n",
       "12       4.154961      0.192741        2.900030       0.037107\n",
       "13       4.150087      0.185076        2.870198       0.039780\n",
       "14       4.156701      0.188260        2.846479       0.037792\n",
       "15       4.145404      0.184212        2.811917       0.036969\n",
       "16       4.141670      0.183382        2.791487       0.034505\n",
       "17       4.139406      0.191476        2.764857       0.032798\n",
       "18       4.134138      0.196838        2.730498       0.030304\n",
       "19       4.120616      0.194074        2.686291       0.025828\n",
       "20       4.115625      0.190053        2.661713       0.024625\n",
       "21       4.111492      0.195630        2.632685       0.026922\n",
       "22       4.106884      0.188216        2.598391       0.026591\n",
       "23       4.109425      0.189713        2.575809       0.034930\n",
       "24       4.106895      0.185098        2.544730       0.030703\n",
       "25       4.103488      0.185234        2.525501       0.031801\n",
       "26       4.098627      0.186998        2.500908       0.027606\n",
       "27       4.098459      0.185767        2.478799       0.029692\n",
       "28       4.098721      0.186931        2.457476       0.027944\n",
       "29       4.093534      0.187031        2.433839       0.019612\n",
       "30       4.092398      0.190349        2.413498       0.019445\n",
       "31       4.092814      0.189468        2.398102       0.020367\n",
       "32       4.094014      0.191986        2.373646       0.023400\n",
       "33       4.090828      0.183624        2.354041       0.021126\n",
       "34       4.091551      0.183067        2.341457       0.014121\n",
       "35       4.092410      0.179464        2.325629       0.011132\n",
       "36       4.086722      0.183275        2.307251       0.014028\n",
       "37       4.082788      0.184458        2.292440       0.011218"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'mae'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0827876000000005"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test-mae-mean'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters max_depth and min_child_weight\n",
    "Those parameters add constraints on the architecture of the trees.\n",
    "\n",
    "max_depth is the maximum number of nodes allowed from the root to the farthest leaf of a tree. Deeper trees can model more complex relationships by adding more nodes, but as we go deeper, splits become less relevant and are sometimes only due to noise, causing the model to overfit.\n",
    "min_child_weight is the minimum weight (or number of samples if all samples have a weight of 1) required in order to create a new node in the tree. A smaller min_child_weight allows the algorithm to create children that correspond to fewer samples, thus allowing for more complex trees, but again, more likely to overfit.\n",
    "Thus, those parameters can be used to control the complexity of the trees. It is important to tune them together in order to find a good trade-off between model bias and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 5), (9, 6), (9, 7), (10, 5), (10, 6), (10, 7), (11, 5), (11, 6), (11, 7)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n",
      "\tMAE 4.04524 for 6 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\tMAE 4.0764622 for 5 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tMAE 4.0753928 for 5 rounds\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "\tMAE 4.0805826000000005 for 5 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\tMAE 4.035100600000001 for 5 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "\tMAE 4.0872416000000005 for 5 rounds\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "\tMAE 4.062633 for 5 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "\tMAE 4.054831999999999 for 5 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\tMAE 4.0581036 for 5 rounds\n",
      "Best params: 10, 6, MAE: 4.035100600000001\n"
     ]
    }
   ],
   "source": [
    "# Define initial best params and MAE\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "\n",
    "    # Update best MAE\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['max_depth'] = 10\n",
    "params['min_child_weight'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 1,\n",
       " 'eta': 0.3,\n",
       " 'eval_metric': 'mae',\n",
       " 'max_depth': 10,\n",
       " 'min_child_weight': 6,\n",
       " 'objective': 'reg:linear',\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those parameters control the sampling of the dataset that is done at each boosting round.\n",
    "\n",
    "Instead of using the whole training set every time, we can build a tree on slightly different data at each step, which makes it less likely to overfit to a single sample or feature.\n",
    "\n",
    "subsample corresponds to the fraction of observations (the rows) to subsample at each step. By default it is set to 1 meaning that we use all rows.\n",
    "colsample_bytree corresponds to the fraction of features (the columns) to use. By default it is set to 1 meaning that we will use all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "\tMAE 4.035100600000001 for 5 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tMAE 4.1112535999999995 for 6 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tMAE 4.15728 for 7 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tMAE 4.327159 for 6 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tMAE 4.115240200000001 for 5 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tMAE 4.1338758 for 5 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tMAE 4.173397 for 7 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tMAE 4.2954372 for 6 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tMAE 4.0704557999999995 for 6 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tMAE 4.083678000000001 for 5 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tMAE 4.1932928 for 5 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tMAE 4.309526199999999 for 7 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tMAE 4.0939432 for 4 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tMAE 4.1591404 for 5 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tMAE 4.2331648 for 5 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tMAE 4.319476400000001 for 7 rounds\n",
      "Best params: 1.0, 1.0, MAE: 4.035100600000001\n"
     ]
    }
   ],
   "source": [
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 1.0,\n",
       " 'eta': 0.3,\n",
       " 'eval_metric': 'mae',\n",
       " 'max_depth': 10,\n",
       " 'min_child_weight': 6,\n",
       " 'objective': 'reg:linear',\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#update dictionary\n",
    "params['subsample'] = 1\n",
    "params['colsample_bytree'] = 1.\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter ETA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ETA parameter controls the learning rate. It corresponds to the shrinkage of the weights associated to features after each round, in other words it defines the amount of \"correction\" we make at each step (remember how each boosting round is correcting the errors of the previous?).\n",
    "\n",
    "In practice, having a lower eta makes our model more robust to overfitting thus, usually, the lower the learning rate, the best. But with a lower eta, we need more boosting rounds, which takes more time to train, sometimes for only marginal improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with eta=0.3\n",
      "\tMAE 4.035100600000001 for 5 rounds\n",
      "\n",
      "CV with eta=0.2\n",
      "\tMAE 4.0020152 for 9 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "\tMAE 3.9625017999999996 for 21 rounds\n",
      "\n",
      "CV with eta=0.05\n",
      "\tMAE 3.9589836 for 42 rounds\n",
      "\n",
      "CV with eta=0.01\n",
      "\tMAE 3.9502756000000003 for 218 rounds\n",
      "\n",
      "Best params: 0.01, MAE: 3.9502756000000003\n"
     ]
    }
   ],
   "source": [
    "# This can take some time…\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for eta in [.3, .2, .1, .05, .01]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "\n",
    "    # Run and time CV\n",
    "    cv_results = xgb.cv(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            seed=42,\n",
    "            nfold=5,\n",
    "            metrics=['mae'],\n",
    "            early_stopping_rounds=10\n",
    "          )\n",
    "\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 1.0,\n",
       " 'eta': 0.01,\n",
       " 'eval_metric': 'mae',\n",
       " 'max_depth': 10,\n",
       " 'min_child_weight': 6,\n",
       " 'objective': 'reg:linear',\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['eta'] = 0.01\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:7.69091\n",
      "Will train until Test-mae hasn't improved in 10 rounds.\n",
      "[1]\tTest-mae:7.62044\n",
      "[2]\tTest-mae:7.55171\n",
      "[3]\tTest-mae:7.48296\n",
      "[4]\tTest-mae:7.41607\n",
      "[5]\tTest-mae:7.35005\n",
      "[6]\tTest-mae:7.28594\n",
      "[7]\tTest-mae:7.22193\n",
      "[8]\tTest-mae:7.15977\n",
      "[9]\tTest-mae:7.09845\n",
      "[10]\tTest-mae:7.03766\n",
      "[11]\tTest-mae:6.97696\n",
      "[12]\tTest-mae:6.91763\n",
      "[13]\tTest-mae:6.85842\n",
      "[14]\tTest-mae:6.8029\n",
      "[15]\tTest-mae:6.74587\n",
      "[16]\tTest-mae:6.69068\n",
      "[17]\tTest-mae:6.63611\n",
      "[18]\tTest-mae:6.58169\n",
      "[19]\tTest-mae:6.52847\n",
      "[20]\tTest-mae:6.47689\n",
      "[21]\tTest-mae:6.42755\n",
      "[22]\tTest-mae:6.37666\n",
      "[23]\tTest-mae:6.32902\n",
      "[24]\tTest-mae:6.28125\n",
      "[25]\tTest-mae:6.23493\n",
      "[26]\tTest-mae:6.18968\n",
      "[27]\tTest-mae:6.14404\n",
      "[28]\tTest-mae:6.10002\n",
      "[29]\tTest-mae:6.05626\n",
      "[30]\tTest-mae:6.01302\n",
      "[31]\tTest-mae:5.96975\n",
      "[32]\tTest-mae:5.92706\n",
      "[33]\tTest-mae:5.88582\n",
      "[34]\tTest-mae:5.84803\n",
      "[35]\tTest-mae:5.80888\n",
      "[36]\tTest-mae:5.77119\n",
      "[37]\tTest-mae:5.73382\n",
      "[38]\tTest-mae:5.69565\n",
      "[39]\tTest-mae:5.65948\n",
      "[40]\tTest-mae:5.62329\n",
      "[41]\tTest-mae:5.58676\n",
      "[42]\tTest-mae:5.55166\n",
      "[43]\tTest-mae:5.51758\n",
      "[44]\tTest-mae:5.48502\n",
      "[45]\tTest-mae:5.45151\n",
      "[46]\tTest-mae:5.42093\n",
      "[47]\tTest-mae:5.39023\n",
      "[48]\tTest-mae:5.35869\n",
      "[49]\tTest-mae:5.32712\n",
      "[50]\tTest-mae:5.2964\n",
      "[51]\tTest-mae:5.26835\n",
      "[52]\tTest-mae:5.24004\n",
      "[53]\tTest-mae:5.21055\n",
      "[54]\tTest-mae:5.18305\n",
      "[55]\tTest-mae:5.15449\n",
      "[56]\tTest-mae:5.12713\n",
      "[57]\tTest-mae:5.10016\n",
      "[58]\tTest-mae:5.07346\n",
      "[59]\tTest-mae:5.04789\n",
      "[60]\tTest-mae:5.0235\n",
      "[61]\tTest-mae:5.0007\n",
      "[62]\tTest-mae:4.97691\n",
      "[63]\tTest-mae:4.95416\n",
      "[64]\tTest-mae:4.93317\n",
      "[65]\tTest-mae:4.91011\n",
      "[66]\tTest-mae:4.88824\n",
      "[67]\tTest-mae:4.86724\n",
      "[68]\tTest-mae:4.84677\n",
      "[69]\tTest-mae:4.82651\n",
      "[70]\tTest-mae:4.80794\n",
      "[71]\tTest-mae:4.79015\n",
      "[72]\tTest-mae:4.77037\n",
      "[73]\tTest-mae:4.7517\n",
      "[74]\tTest-mae:4.73482\n",
      "[75]\tTest-mae:4.71909\n",
      "[76]\tTest-mae:4.70175\n",
      "[77]\tTest-mae:4.68487\n",
      "[78]\tTest-mae:4.66649\n",
      "[79]\tTest-mae:4.65053\n",
      "[80]\tTest-mae:4.63511\n",
      "[81]\tTest-mae:4.61966\n",
      "[82]\tTest-mae:4.60259\n",
      "[83]\tTest-mae:4.58859\n",
      "[84]\tTest-mae:4.57424\n",
      "[85]\tTest-mae:4.56077\n",
      "[86]\tTest-mae:4.54654\n",
      "[87]\tTest-mae:4.53386\n",
      "[88]\tTest-mae:4.5214\n",
      "[89]\tTest-mae:4.50779\n",
      "[90]\tTest-mae:4.49576\n",
      "[91]\tTest-mae:4.48318\n",
      "[92]\tTest-mae:4.47056\n",
      "[93]\tTest-mae:4.45875\n",
      "[94]\tTest-mae:4.44642\n",
      "[95]\tTest-mae:4.43464\n",
      "[96]\tTest-mae:4.42302\n",
      "[97]\tTest-mae:4.41236\n",
      "[98]\tTest-mae:4.40327\n",
      "[99]\tTest-mae:4.39273\n",
      "[100]\tTest-mae:4.38211\n",
      "[101]\tTest-mae:4.3727\n",
      "[102]\tTest-mae:4.36262\n",
      "[103]\tTest-mae:4.35321\n",
      "[104]\tTest-mae:4.34387\n",
      "[105]\tTest-mae:4.33374\n",
      "[106]\tTest-mae:4.32414\n",
      "[107]\tTest-mae:4.31417\n",
      "[108]\tTest-mae:4.3046\n",
      "[109]\tTest-mae:4.29538\n",
      "[110]\tTest-mae:4.28666\n",
      "[111]\tTest-mae:4.27911\n",
      "[112]\tTest-mae:4.2723\n",
      "[113]\tTest-mae:4.26583\n",
      "[114]\tTest-mae:4.25864\n",
      "[115]\tTest-mae:4.25137\n",
      "[116]\tTest-mae:4.24511\n",
      "[117]\tTest-mae:4.23814\n",
      "[118]\tTest-mae:4.23128\n",
      "[119]\tTest-mae:4.22532\n",
      "[120]\tTest-mae:4.21852\n",
      "[121]\tTest-mae:4.21136\n",
      "[122]\tTest-mae:4.2061\n",
      "[123]\tTest-mae:4.20087\n",
      "[124]\tTest-mae:4.1965\n",
      "[125]\tTest-mae:4.19055\n",
      "[126]\tTest-mae:4.18594\n",
      "[127]\tTest-mae:4.18161\n",
      "[128]\tTest-mae:4.17668\n",
      "[129]\tTest-mae:4.17174\n",
      "[130]\tTest-mae:4.16783\n",
      "[131]\tTest-mae:4.16379\n",
      "[132]\tTest-mae:4.15763\n",
      "[133]\tTest-mae:4.15399\n",
      "[134]\tTest-mae:4.15106\n",
      "[135]\tTest-mae:4.14729\n",
      "[136]\tTest-mae:4.14475\n",
      "[137]\tTest-mae:4.14189\n",
      "[138]\tTest-mae:4.13933\n",
      "[139]\tTest-mae:4.13663\n",
      "[140]\tTest-mae:4.13382\n",
      "[141]\tTest-mae:4.1313\n",
      "[142]\tTest-mae:4.12923\n",
      "[143]\tTest-mae:4.12666\n",
      "[144]\tTest-mae:4.12476\n",
      "[145]\tTest-mae:4.12357\n",
      "[146]\tTest-mae:4.12251\n",
      "[147]\tTest-mae:4.1213\n",
      "[148]\tTest-mae:4.12124\n",
      "[149]\tTest-mae:4.12152\n",
      "[150]\tTest-mae:4.12136\n",
      "[151]\tTest-mae:4.12266\n",
      "[152]\tTest-mae:4.12398\n",
      "[153]\tTest-mae:4.12522\n",
      "[154]\tTest-mae:4.12691\n",
      "[155]\tTest-mae:4.12817\n",
      "[156]\tTest-mae:4.12729\n",
      "[157]\tTest-mae:4.1286\n",
      "[158]\tTest-mae:4.12991\n",
      "Stopping. Best iteration:\n",
      "[148]\tTest-mae:4.12124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#try on test set\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE: 4.12 in 149 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best MAE: {:.2f} in {} rounds\".format(model.best_score, model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:7.69091\n",
      "[1]\tTest-mae:7.62044\n",
      "[2]\tTest-mae:7.55171\n",
      "[3]\tTest-mae:7.48296\n",
      "[4]\tTest-mae:7.41607\n",
      "[5]\tTest-mae:7.35005\n",
      "[6]\tTest-mae:7.28594\n",
      "[7]\tTest-mae:7.22193\n",
      "[8]\tTest-mae:7.15977\n",
      "[9]\tTest-mae:7.09845\n",
      "[10]\tTest-mae:7.03766\n",
      "[11]\tTest-mae:6.97696\n",
      "[12]\tTest-mae:6.91763\n",
      "[13]\tTest-mae:6.85842\n",
      "[14]\tTest-mae:6.8029\n",
      "[15]\tTest-mae:6.74587\n",
      "[16]\tTest-mae:6.69068\n",
      "[17]\tTest-mae:6.63611\n",
      "[18]\tTest-mae:6.58169\n",
      "[19]\tTest-mae:6.52847\n",
      "[20]\tTest-mae:6.47689\n",
      "[21]\tTest-mae:6.42755\n",
      "[22]\tTest-mae:6.37666\n",
      "[23]\tTest-mae:6.32902\n",
      "[24]\tTest-mae:6.28125\n",
      "[25]\tTest-mae:6.23493\n",
      "[26]\tTest-mae:6.18968\n",
      "[27]\tTest-mae:6.14404\n",
      "[28]\tTest-mae:6.10002\n",
      "[29]\tTest-mae:6.05626\n",
      "[30]\tTest-mae:6.01302\n",
      "[31]\tTest-mae:5.96975\n",
      "[32]\tTest-mae:5.92706\n",
      "[33]\tTest-mae:5.88582\n",
      "[34]\tTest-mae:5.84803\n",
      "[35]\tTest-mae:5.80888\n",
      "[36]\tTest-mae:5.77119\n",
      "[37]\tTest-mae:5.73382\n",
      "[38]\tTest-mae:5.69565\n",
      "[39]\tTest-mae:5.65948\n",
      "[40]\tTest-mae:5.62329\n",
      "[41]\tTest-mae:5.58676\n",
      "[42]\tTest-mae:5.55166\n",
      "[43]\tTest-mae:5.51758\n",
      "[44]\tTest-mae:5.48502\n",
      "[45]\tTest-mae:5.45151\n",
      "[46]\tTest-mae:5.42093\n",
      "[47]\tTest-mae:5.39023\n",
      "[48]\tTest-mae:5.35869\n",
      "[49]\tTest-mae:5.32712\n",
      "[50]\tTest-mae:5.2964\n",
      "[51]\tTest-mae:5.26835\n",
      "[52]\tTest-mae:5.24004\n",
      "[53]\tTest-mae:5.21055\n",
      "[54]\tTest-mae:5.18305\n",
      "[55]\tTest-mae:5.15449\n",
      "[56]\tTest-mae:5.12713\n",
      "[57]\tTest-mae:5.10016\n",
      "[58]\tTest-mae:5.07346\n",
      "[59]\tTest-mae:5.04789\n",
      "[60]\tTest-mae:5.0235\n",
      "[61]\tTest-mae:5.0007\n",
      "[62]\tTest-mae:4.97691\n",
      "[63]\tTest-mae:4.95416\n",
      "[64]\tTest-mae:4.93317\n",
      "[65]\tTest-mae:4.91011\n",
      "[66]\tTest-mae:4.88824\n",
      "[67]\tTest-mae:4.86724\n",
      "[68]\tTest-mae:4.84677\n",
      "[69]\tTest-mae:4.82651\n",
      "[70]\tTest-mae:4.80794\n",
      "[71]\tTest-mae:4.79015\n",
      "[72]\tTest-mae:4.77037\n",
      "[73]\tTest-mae:4.7517\n",
      "[74]\tTest-mae:4.73482\n",
      "[75]\tTest-mae:4.71909\n",
      "[76]\tTest-mae:4.70175\n",
      "[77]\tTest-mae:4.68487\n",
      "[78]\tTest-mae:4.66649\n",
      "[79]\tTest-mae:4.65053\n",
      "[80]\tTest-mae:4.63511\n",
      "[81]\tTest-mae:4.61966\n",
      "[82]\tTest-mae:4.60259\n",
      "[83]\tTest-mae:4.58859\n",
      "[84]\tTest-mae:4.57424\n",
      "[85]\tTest-mae:4.56077\n",
      "[86]\tTest-mae:4.54654\n",
      "[87]\tTest-mae:4.53386\n",
      "[88]\tTest-mae:4.5214\n",
      "[89]\tTest-mae:4.50779\n",
      "[90]\tTest-mae:4.49576\n",
      "[91]\tTest-mae:4.48318\n",
      "[92]\tTest-mae:4.47056\n",
      "[93]\tTest-mae:4.45875\n",
      "[94]\tTest-mae:4.44642\n",
      "[95]\tTest-mae:4.43464\n",
      "[96]\tTest-mae:4.42302\n",
      "[97]\tTest-mae:4.41236\n",
      "[98]\tTest-mae:4.40327\n",
      "[99]\tTest-mae:4.39273\n",
      "[100]\tTest-mae:4.38211\n",
      "[101]\tTest-mae:4.3727\n",
      "[102]\tTest-mae:4.36262\n",
      "[103]\tTest-mae:4.35321\n",
      "[104]\tTest-mae:4.34387\n",
      "[105]\tTest-mae:4.33374\n",
      "[106]\tTest-mae:4.32414\n",
      "[107]\tTest-mae:4.31417\n",
      "[108]\tTest-mae:4.3046\n",
      "[109]\tTest-mae:4.29538\n",
      "[110]\tTest-mae:4.28666\n",
      "[111]\tTest-mae:4.27911\n",
      "[112]\tTest-mae:4.2723\n",
      "[113]\tTest-mae:4.26583\n",
      "[114]\tTest-mae:4.25864\n",
      "[115]\tTest-mae:4.25137\n",
      "[116]\tTest-mae:4.24511\n",
      "[117]\tTest-mae:4.23814\n",
      "[118]\tTest-mae:4.23128\n",
      "[119]\tTest-mae:4.22532\n",
      "[120]\tTest-mae:4.21852\n",
      "[121]\tTest-mae:4.21136\n",
      "[122]\tTest-mae:4.2061\n",
      "[123]\tTest-mae:4.20087\n",
      "[124]\tTest-mae:4.1965\n",
      "[125]\tTest-mae:4.19055\n",
      "[126]\tTest-mae:4.18594\n",
      "[127]\tTest-mae:4.18161\n",
      "[128]\tTest-mae:4.17668\n",
      "[129]\tTest-mae:4.17174\n",
      "[130]\tTest-mae:4.16783\n",
      "[131]\tTest-mae:4.16379\n",
      "[132]\tTest-mae:4.15763\n",
      "[133]\tTest-mae:4.15399\n",
      "[134]\tTest-mae:4.15106\n",
      "[135]\tTest-mae:4.14729\n",
      "[136]\tTest-mae:4.14475\n",
      "[137]\tTest-mae:4.14189\n",
      "[138]\tTest-mae:4.13933\n",
      "[139]\tTest-mae:4.13663\n",
      "[140]\tTest-mae:4.13382\n",
      "[141]\tTest-mae:4.1313\n",
      "[142]\tTest-mae:4.12923\n",
      "[143]\tTest-mae:4.12666\n",
      "[144]\tTest-mae:4.12476\n",
      "[145]\tTest-mae:4.12357\n",
      "[146]\tTest-mae:4.12251\n",
      "[147]\tTest-mae:4.1213\n",
      "[148]\tTest-mae:4.12124\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = model.best_iteration + 1\n",
    "\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.121239465908108"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(best_model.predict(dtest), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model.save_model(\"my_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.6986032 , 0.33287936, 1.8307076 , ..., 3.327849  , 0.16464412,\n",
       "       3.212406  ], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = xgb.Booster()\n",
    "loaded_model.load_model(\"my_model.model\")\n",
    "\n",
    "# And use it for predictions.\n",
    "loaded_model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x10870acc0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
